{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, os, datetime\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from jobspy import scrape_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "ids are unique, global static\n",
    "\n",
    "RUN\n",
    " -  GET USER CONFIGS\n",
    " -  GET DATE\n",
    "\n",
    " - FOR EACH USER CONFIG\n",
    "\n",
    "    - For each search_setting\n",
    "\n",
    "        - For each KW\n",
    "\n",
    "            - Find Jobs\n",
    "    \n",
    "    - Generate Reports and Stats\n",
    "\n",
    "\n",
    "    LOGGING\n",
    "\n",
    "    - Log all errors and warnings\n",
    "    - Log all successful runs\n",
    "    - Log all failed runs\n",
    "\n",
    "     [RUN-LOGS-(package)-E-Mail]\n",
    "\n",
    "     encypted zip - stats.csv, sigma_quo.txt, \n",
    "\n",
    "     - polymorphic/other dp, encap, graph inherit\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> Config file paths found : ['users/tdawg/tdawg_config.json', 'users/lucky/lucky_config.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user': 'tdawg', 'email': 'test@test.de'},\n",
       " {'user': 'lucky',\n",
       "  'email': 's4mipojo@uni-trier.de',\n",
       "  'jobs': [{'id': 1,\n",
       "    'name': 'lux_py',\n",
       "    'site_name': ['indeed'],\n",
       "    'search_terms': ['', 'python', 'database'],\n",
       "    'results_wanted': 500,\n",
       "    'hours_old': 72,\n",
       "    'is_remote': False,\n",
       "    'country_indeed': 'luxembourg',\n",
       "    'proxy': 'proxy',\n",
       "    'run_count': 0,\n",
       "    'run_left': 0,\n",
       "    'created': '2016-01-01T00:00:00Z',\n",
       "    'updated': '2016-01-01T00:00:00Z'},\n",
       "   {'id': 2,\n",
       "    'name': 'ger_py',\n",
       "    'site_name': ['indeed'],\n",
       "    'search_terms': ['', 'python', 'database'],\n",
       "    'results_wanted': 500,\n",
       "    'hours_old': 72,\n",
       "    'is_remote': True,\n",
       "    'country_indeed': 'germany',\n",
       "    'proxy': 'proxy',\n",
       "    'status': 'running',\n",
       "    'created': '2016-01-01T00:00:00Z',\n",
       "    'updated': '2016-01-01T00:00:00Z'}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, attribute1):\n",
    "        self.attribute1 = attribute1\n",
    "        self.attribute2 = get_user_configs()\n",
    "        # date, proxy, user_configs\n",
    "\n",
    "    def my_method(self):\n",
    "        print(f\"Attribute value is {self.attribute1}\")\n",
    "\n",
    "\n",
    "# --- INIT --- #\n",
    "def get_user_configs() -> list[dict]: \n",
    "\n",
    "    user_config_paths = glob.glob('users/**/*.json')\n",
    "    print(f\" ---> Config file paths found : {user_config_paths}\")\n",
    "    user_configs = []\n",
    "\n",
    "    for user_config_path in user_config_paths:\n",
    "        with open(user_config_path) as f:\n",
    "            tmp_dict = json.load(f)\n",
    "            user_configs.append(tmp_dict)\n",
    "    \n",
    "    return user_configs\n",
    "\n",
    "def get_date() -> str:\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    return date\n",
    "\n",
    "\n",
    "def get_proxy() -> str:\n",
    "    \n",
    "    proxy_path = os.path.join(\"results\", \"proxy.txt\")\n",
    "    with open(proxy_path, \"r\") as f:\n",
    "        proxy = f.read().strip()\n",
    "\n",
    "    return proxy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- SEARCH --- #\n",
    "\n",
    "def update_keywords_left(keywords: list, date: str) -> list:\n",
    "    \n",
    "    files = glob.glob(\"results/*.csv\")\n",
    "    files = [os.path.basename(file) for file in files]\n",
    "\n",
    "    keywords_done = [keyword for keyword in keywords if f\"{keyword}_{date}.csv\" in files]\n",
    "    keywords_left = [keyword for keyword in keywords if keyword not in keywords_done]\n",
    "\n",
    "    print(f\"--- Date: {date} ---\")\n",
    "    print(f\"Keywords done: {len(keywords_done)} : {keywords_done}\")\n",
    "    print(f\"Keywords left: {len(keywords_left)} : {keywords_left}\")\n",
    "    return keywords_left\n",
    "\n",
    "\n",
    "\n",
    "def run_keyword(keyword: str) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return jobs\n",
    "\n",
    "\n",
    "\n",
    "def filter_jobs(jobs: pd.DataFrame, search_setting: dict) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def run_search_setting(search_setting: dict, date: str) -> None:\n",
    "        \n",
    "    empty_jobs = pd.DataFrame(columns=[ \"job_url\",\n",
    "    \"site\", \"title\", \"company\", \"company_url\", \"location\", \"job_type\",\n",
    "    \"date_posted\", \"interval\", \"min_amount\", \"max_amount\", \"currency\",\n",
    "    \"is_remote\", \"num_urgent_words\", \"benefits\", \"emails\", \"description\"])\n",
    "\n",
    "    keywords = search_setting['keywords']\n",
    "    jobs = empty_jobs\n",
    "\n",
    "\n",
    "    # ---  the RUN PROGRESS (based on exceptions) \n",
    "    # --- if files is populated, it gets stored(even if incomplete) \n",
    "    keywords_left = update_keywords_left(keywords, date)\n",
    "\n",
    "\n",
    "\n",
    "    for \n",
    "\n",
    "\n",
    "\n",
    "def run_user() -> None:\n",
    "    pass\n",
    "\n",
    "def send_logs() -> None:\n",
    "    pass\n",
    "\n",
    "def run_all_users():\n",
    "\n",
    "    date = get_date()\n",
    "    user_configs = get_user_configs()\n",
    "\n",
    "    proxy_path = os.path.join(\"results\", \"proxy.txt\")\n",
    "    with open(proxy_path, \"r\") as f:\n",
    "        proxy = f.read().strip()\n",
    "\n",
    "    print(f\" ---> Date : {date}\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-jobspy-gxDDdTXR-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
